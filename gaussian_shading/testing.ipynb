{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import CLIPModel, CLIPTokenizer\n",
    "from inverse_stable_diffusion import InversableStableDiffusionPipeline\n",
    "from diffusers import DPMSolverMultistepScheduler, DDIMScheduler\n",
    "import open_clip\n",
    "from optim_utils import *\n",
    "from io_utils import *\n",
    "from image_utils import *\n",
    "from watermark import *\n",
    "import re\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "from diffusers import AutoPipelineForImage2Image\n",
    "import random\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/raid/home/ashhar21137/watermarking2/captions_train2014_new_format.json','r') as file : \n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/raid/home/ashhar21137/watermarking2/original_images'\n",
    "img_ids = []\n",
    "img_pths = []\n",
    "imgs = os.listdir(img_dir)\n",
    "for i in imgs : \n",
    "    id = re.split('[_.]',i)[1]\n",
    "    img_ids.append(id) \n",
    "    img_pths.append(os.path.join(img_dir,i))\n",
    "\n",
    "print(f'img_ids : {img_ids}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captions = []\n",
    "# for id in img_ids : \n",
    "#     captions.append(data['annotations'][id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data['annotations']['79481'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['annotations']['79481'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_model = None \n",
    "reference_model_pretrain = None \n",
    "model_path = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "channel_copy = 1 \n",
    "hw_copy = 8 \n",
    "fpr = 0.000001\n",
    "num = 1000\n",
    "user_number = 1000000\n",
    "output_path = \"/raid/home/ashhar21137/watermarking2/Gaussian-Shading/gs_watermarked_images_2\"\n",
    "gen_seed = 0 \n",
    "num_inference_steps = 50 \n",
    "guidance_scale = 7.5\n",
    "image_length = 512\n",
    "chacha = True\n",
    "num_inversion_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_brightness = SimpleNamespace(\n",
    "    reference_model = None ,\n",
    "    reference_model_pretrain = None ,\n",
    "    model_path = \"stabilityai/stable-diffusion-2-1-base\",\n",
    "    channel_copy = 1 ,\n",
    "    hw_copy = 8 ,\n",
    "    fpr = 0.000001,\n",
    "    num = 1000,\n",
    "    user_number = 1000000,\n",
    "    output_path = \"/raid/home/ashhar21137/watermarking2/Gaussian-Shading/watermarked_images\",\n",
    "    gen_seed = 0 ,\n",
    "    num_inference_steps = 50 ,\n",
    "    guidance_scale = 7.5,\n",
    "    image_length = 512,\n",
    "    chacha = True,\n",
    "    num_inversion_steps = 50,\n",
    "    jpeg_ratio = None,\n",
    "    random_crop_ratio =None ,\n",
    "    random_drop_ratio = None, \n",
    "    gaussian_blur_r = None, \n",
    "    median_blur_k = None, \n",
    "    resize_ratio = None, \n",
    "    gaussian_std = None, \n",
    "    sp_prob = None, \n",
    "    brightness_factor = 2,\n",
    "    rotate_deg = None \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_jpeg = SimpleNamespace(\n",
    "    reference_model = None ,\n",
    "    reference_model_pretrain = None ,\n",
    "    model_path = \"stabilityai/stable-diffusion-2-1-base\",\n",
    "    channel_copy = 1 ,\n",
    "    hw_copy = 8 ,\n",
    "    fpr = 0.000001,\n",
    "    num = 1000,\n",
    "    user_number = 1000000,\n",
    "    output_path = \"/raid/home/ashhar21137/watermarking2/Gaussian-Shading/watermarked_images\",\n",
    "    gen_seed = 0 ,\n",
    "    num_inference_steps = 50 ,\n",
    "    guidance_scale = 7.5,\n",
    "    image_length = 512,\n",
    "    chacha = True,\n",
    "    num_inversion_steps = 50,\n",
    "    jpeg_ratio = 50,\n",
    "    random_crop_ratio =None ,\n",
    "    random_drop_ratio = None, \n",
    "    gaussian_blur_r = None, \n",
    "    median_blur_k = None, \n",
    "    resize_ratio = None, \n",
    "    gaussian_std = None, \n",
    "    sp_prob = None, \n",
    "    brightness_factor = None,\n",
    "    rotate_deg = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gaussian_noise = SimpleNamespace(\n",
    "    reference_model = None ,\n",
    "    reference_model_pretrain = None ,\n",
    "    model_path = \"stabilityai/stable-diffusion-2-1-base\",\n",
    "    channel_copy = 1 ,\n",
    "    hw_copy = 8 ,\n",
    "    fpr = 0.000001,\n",
    "    num = 1000,\n",
    "    user_number = 1000000,\n",
    "    output_path = \"/raid/home/ashhar21137/watermarking2/Gaussian-Shading/watermarked_images\",\n",
    "    gen_seed = 0 ,\n",
    "    num_inference_steps = 50 ,\n",
    "    guidance_scale = 7.5,\n",
    "    image_length = 512,\n",
    "    chacha = True,\n",
    "    num_inversion_steps = 50,\n",
    "    jpeg_ratio = None,\n",
    "    random_crop_ratio =None ,\n",
    "    random_drop_ratio = None, \n",
    "    gaussian_blur_r = None, \n",
    "    median_blur_k = None, \n",
    "    resize_ratio = None, \n",
    "    gaussian_std = 0.1, \n",
    "    sp_prob = None, \n",
    "    brightness_factor = None,\n",
    "    rotate_deg = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_rotate = SimpleNamespace(\n",
    "    reference_model = None ,\n",
    "    reference_model_pretrain = None ,\n",
    "    model_path = \"stabilityai/stable-diffusion-2-1-base\",\n",
    "    channel_copy = 1 ,\n",
    "    hw_copy = 8 ,\n",
    "    fpr = 0.000001,\n",
    "    num = 1000,\n",
    "    user_number = 1000000,\n",
    "    output_path = \"/raid/home/ashhar21137/watermarking2/Gaussian-Shading/watermarked_images\",\n",
    "    gen_seed = 0 ,\n",
    "    num_inference_steps = 50 ,\n",
    "    guidance_scale = 7.5,\n",
    "    image_length = 512,\n",
    "    chacha = True,\n",
    "    num_inversion_steps = 50,\n",
    "    jpeg_ratio = None,\n",
    "    random_crop_ratio =None ,\n",
    "    random_drop_ratio = None, \n",
    "    gaussian_blur_r = None, \n",
    "    median_blur_k = None, \n",
    "    resize_ratio = None, \n",
    "    gaussian_std = None, \n",
    "    sp_prob = None, \n",
    "    brightness_factor = None,\n",
    "    rotate_deg = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = [\"brightness\",\"gaussian_noise\",\"jpeg\",\"rotation\"]\n",
    "attacks_op_parent = \"/raid/home/ashhar21137/watermarking2/Gaussian-Shading/gs_attacked_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_model_id = 'stabilityai/stable-diffusion-xl-base-1.0'\n",
    "pipeline_text2image = AutoPipelineForText2Image.from_pretrained(paraphrase_model_id, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True, add_watermarker=False).to(device)\n",
    "pipeline = AutoPipelineForImage2Image.from_pipe(pipeline_text2image).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_excluding_index(lst, i):\n",
    "    # Remove the element at the i-th index\n",
    "    excluded_list = lst[:i] + lst[i+1:]\n",
    "    # Select a random element from the remaining list\n",
    "    selected_element = random.choice(excluded_list)\n",
    "    return selected_element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "og_detection_dict = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "attack_detection = defaultdict(lambda: defaultdict(dict))\n",
    "paraphrase_detection = defaultdict(lambda: defaultdict(lambda: {'avg_probability': 0, 'detection_rate': 0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1 \n",
    "for id in tqdm(img_ids):\n",
    "    if count > 5 : break \n",
    "\n",
    "    print(f\"******** Count : {count} ********\")\n",
    "\n",
    "    scheduler = DPMSolverMultistepScheduler.from_pretrained(model_path, subfolder='scheduler')\n",
    "    pipe = InversableStableDiffusionPipeline.from_pretrained(\n",
    "            model_path,\n",
    "            scheduler=scheduler,\n",
    "            torch_dtype=torch.float16,\n",
    "            revision='fp16',\n",
    "    )\n",
    "    pipe.safety_checker = None\n",
    "    pipe = pipe.to(device)\n",
    "\n",
    "    #reference model for CLIP Score\n",
    "    if reference_model is not None:\n",
    "        ref_model, _, ref_clip_preprocess = open_clip.create_model_and_transforms(reference_model,\n",
    "                                                                                    pretrained=reference_model_pretrain,\n",
    "                                                                                    device=device)\n",
    "        ref_tokenizer = open_clip.get_tokenizer(reference_model)\n",
    "\n",
    "    # dataset\n",
    "    # dataset, prompt_key = get_dataset(args)\n",
    "\n",
    "    # class for watermark\n",
    "    if chacha:\n",
    "        watermark = Gaussian_Shading_chacha(channel_copy, hw_copy, fpr, user_number)\n",
    "    else:\n",
    "        #a simple implement,\n",
    "        watermark = Gaussian_Shading(channel_copy, hw_copy, fpr, user_number)\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # assume at the detection time, the original prompt is unknown\n",
    "    tester_prompt = ''\n",
    "    text_embeddings = pipe.get_text_embedding(tester_prompt)\n",
    "\n",
    "    #acc\n",
    "    acc = []\n",
    "    #CLIP Scores\n",
    "    clip_scores = []\n",
    "\n",
    "    captions = data['annotations'][id]\n",
    "\n",
    "    print(f\"len captions : {len(captions)}\")\n",
    "\n",
    "    for attack in attacks: \n",
    "        attack_detection[id][attack]['avg_probability'] = 0 \n",
    "        attack_detection[id][attack]['detection_rate'] = 0 \n",
    "\n",
    "    #test\n",
    "    for i in tqdm(range(len(captions))):\n",
    "        seed = i + gen_seed\n",
    "        current_prompt = captions[i]\n",
    "\n",
    "        #generate with watermark\n",
    "        set_random_seed(seed)\n",
    "        init_latents_w = watermark.create_watermark_and_return_w()\n",
    "        outputs = pipe(\n",
    "            current_prompt,\n",
    "            num_images_per_prompt=1,\n",
    "            guidance_scale=guidance_scale,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            height=image_length,\n",
    "            width=image_length,\n",
    "            latents=init_latents_w,\n",
    "        )\n",
    "        image_w = outputs.images[0]\n",
    "\n",
    "        watermarked_image = image_w\n",
    "\n",
    "        if not isinstance(watermarked_image, Image.Image):\n",
    "            watermarked_image = Image.fromarray(image_w)\n",
    "\n",
    "        directory = f'/raid/home/ashhar21137/watermarking2/Gaussian-Shading/gs_watermarked_images_2/{id}'\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        filename = f'{id}_watermarked_caption_{i}.png'\n",
    "        watermarked_image.save(os.path.join(directory, filename))\n",
    "        print(f\"Image saved to {os.path.join(directory, filename)}\")\n",
    "\n",
    "        # image_w_distortion = image_distortion(image_w, seed, args)\n",
    "\n",
    "        image_og = image_w\n",
    "\n",
    "        # reverse img\n",
    "        image_og = transform_img(image_og).unsqueeze(0).to(text_embeddings.dtype).to(device)\n",
    "        image_latents_w = pipe.get_image_latents(image_og, sample=False)\n",
    "        reversed_latents_w = pipe.forward_diffusion(\n",
    "            latents=image_latents_w,\n",
    "            text_embeddings=text_embeddings,\n",
    "            guidance_scale=1,\n",
    "            num_inference_steps=num_inversion_steps,\n",
    "        )\n",
    "\n",
    "        #acc metric\n",
    "        acc_metric = watermark.eval_watermark(reversed_latents_w)\n",
    "        print(\"acc_metric : \", acc_metric)\n",
    "        acc.append(acc_metric)\n",
    "\n",
    "        og_detection_dict[id][f\"caption{i}\"] = acc_metric\n",
    "\n",
    "        for attack in attacks:\n",
    "            if attack == \"brightness\": \n",
    "                image_w_distortion = image_distortion(image_w, seed, args_brightness)\n",
    "            elif attack == \"jpeg\":\n",
    "                image_w_distortion = image_distortion(image_w, seed, args_jpeg)\n",
    "            elif attack == \"gaussian_noise\": \n",
    "                image_w_distortion = image_distortion(image_w, seed, args_gaussian_noise)\n",
    "            elif attack == \"rotation\": \n",
    "                image_w_distortion = image_distortion(image_w, seed, args_rotate)\n",
    "\n",
    "            print(f\"attack : {attack}\")\n",
    "\n",
    "            if not isinstance(image_w_distortion, Image.Image):\n",
    "                image_w_distortion = Image.fromarray(image_w_distortion)\n",
    "\n",
    "            # Create the directory if it doesn't exist\n",
    "            att_save = f\"{attacks_op_parent}/{attack}/{id}\"\n",
    "            if not os.path.exists(att_save):\n",
    "                os.makedirs(att_save)\n",
    "\n",
    "            filename_att = f'{attack}_{id}_watermarked_caption_{i}.png'\n",
    "            image_w_distortion.save(os.path.join(att_save, filename_att))\n",
    "            print(f\" {attack} Image saved to {os.path.join(att_save, filename_att)}\")\n",
    "\n",
    "            image_w_distortion = transform_img(image_w_distortion).unsqueeze(0).to(text_embeddings.dtype).to(device)\n",
    "            image_latents_w = pipe.get_image_latents(image_w_distortion, sample=False)\n",
    "            reversed_latents_w = pipe.forward_diffusion(\n",
    "                latents=image_latents_w,\n",
    "                text_embeddings=text_embeddings,\n",
    "                guidance_scale=1,\n",
    "                num_inference_steps=num_inversion_steps,\n",
    "            )\n",
    "\n",
    "            #acc metric\n",
    "            acc_metric = watermark.eval_watermark(reversed_latents_w)\n",
    "            print(f\" attack : {attack} | acc_metric : {acc_metric}\")\n",
    "            # acc.append(acc_metric)\n",
    "\n",
    "            attack_detection[id][attack]['avg_probability'] += acc_metric / len(captions)\n",
    "            attack_detection[id][attack]['detection_rate'] += (acc_metric > 0.9) / len(captions)\n",
    "\n",
    "        # Paraphrasing \n",
    "        # paraphrase_caption = captions[i]\n",
    "        paraphrase_caption = select_random_excluding_index(captions,i)\n",
    "\n",
    "        gen_image = pipeline(paraphrase_caption, image=image_w, strength=0.16, guidance_scale=7.5).images\n",
    "\n",
    "        directory_paraphrased = f'/raid/home/ashhar21137/watermarking2/Gaussian-Shading/gs_wm_0.15_paraphrased/strength_0.15/{id}'\n",
    "        print(f\"Saving generated images at {directory_paraphrased}\")\n",
    "        if not os.path.exists(directory_paraphrased):\n",
    "            os.makedirs(directory_paraphrased)\n",
    "\n",
    "        paraphrased_name = f'gen_{id}_{i}.png'\n",
    "        # print(len(gen_image))\n",
    "\n",
    "        gen_image = gen_image[0]\n",
    "\n",
    "        gen_image.save(os.path.join(directory_paraphrased, paraphrased_name))\n",
    "        print(f\" Paraphrased Image saved to {os.path.join(directory_paraphrased, paraphrased_name)}\")\n",
    "\n",
    "        # Ensure gen_image is a PIL Image\n",
    "        if not isinstance(gen_image, Image.Image):\n",
    "            gen_image = Image.fromarray(gen_image)\n",
    "\n",
    "        # *** Testing with captions **\n",
    "        tester_prompt = ''\n",
    "        text_embeddings = pipe.get_text_embedding(paraphrase_caption)\n",
    "\n",
    "        gen_image1 = transform_img(gen_image).unsqueeze(0).to(text_embeddings.dtype).to(device)\n",
    "        gen_image_latents_w = pipe.get_image_latents(gen_image1, sample=False)\n",
    "        gen_reversed_latents_w = pipe.forward_diffusion(\n",
    "            latents=gen_image_latents_w,\n",
    "            text_embeddings=text_embeddings,\n",
    "            guidance_scale=1,\n",
    "            num_inference_steps=num_inversion_steps,\n",
    "        )\n",
    "\n",
    "        #acc metric\n",
    "        gen_acc_metric = watermark.eval_watermark(gen_reversed_latents_w)\n",
    "        print(f\" attack : Paraphrase | acc_metric : {gen_acc_metric}\")\n",
    "        # acc.append(acc_metric)\n",
    "\n",
    "        paraphrase_detection[id]['with_caption']['avg_probability'] += gen_acc_metric / len(captions)\n",
    "        paraphrase_detection[id]['with_caption']['detection_rate'] += (gen_acc_metric > 0.9) / len(captions)\n",
    "\n",
    "        # *** Testing without captions **\n",
    "        tester_prompt = ''\n",
    "        text_embeddings = pipe.get_text_embedding(tester_prompt)\n",
    "\n",
    "        gen_image2 = transform_img(gen_image).unsqueeze(0).to(text_embeddings.dtype).to(device)\n",
    "        gen_image_latents_w = pipe.get_image_latents(gen_image2, sample=False)\n",
    "        gen_reversed_latents_w = pipe.forward_diffusion(\n",
    "            latents=gen_image_latents_w,\n",
    "            text_embeddings=text_embeddings,\n",
    "            guidance_scale=1,\n",
    "            num_inference_steps=num_inversion_steps,\n",
    "        )\n",
    "\n",
    "        #acc metric\n",
    "        gen_acc_metric = watermark.eval_watermark(gen_reversed_latents_w)\n",
    "        print(f\" attack : Paraphrase | acc_metric : {gen_acc_metric}\")\n",
    "        # acc.append(acc_metric)\n",
    "\n",
    "        paraphrase_detection[id]['without_caption']['avg_probability'] += gen_acc_metric / len(captions)\n",
    "        paraphrase_detection[id]['without_caption']['detection_rate'] += (gen_acc_metric > 0.9) / len(captions)\n",
    "\n",
    "    # break \n",
    "\n",
    "    count = count + 1 \n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrase_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = '79481_watermarked_caption_0'\n",
    "\n",
    "int(st.split(\".\")[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'gs_paraphrase_detection.json','w') as file : \n",
    "    json.dump(paraphrase_detection,file,indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_gaussian_shading.py \\\n",
    "      --fpr 0.000001 \\\n",
    "      --channel_copy 1 \\\n",
    "      --hw_copy 8 \\\n",
    "      --chacha \\\n",
    "      --num 1000 \\\n",
    "      --reference_model ViT-g-14 \\\n",
    "      --reference_model_pretrain laion2b_s12b_b42k \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zodiac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
